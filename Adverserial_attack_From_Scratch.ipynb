{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "htEfvVCa7EYc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms,datasets\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7yujbSv7jHP",
        "outputId": "88bf67be-d9d8-4451-901c-35c35299a53a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f05ec414d50>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "])"
      ],
      "metadata": {
        "id": "E7KYo7baEung"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataset = datasets.CIFAR10(root = './data', train=True, transform = transform_train, download=True)\n",
        "train_set, val_set = torch.utils.data.random_split(dataset, [40000,10000])\n",
        "\n",
        "\n",
        "testset = datasets.CIFAR10(root = './data', train=False, transform = transform_test, download=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_set,batch_size=100,shuffle=True)\n",
        "\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_set,batch_size=100,shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(testset,batch_size=1,shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arXcOzbr7jgu",
        "outputId": "7e6c390b-9d75-411f-d631-f1ee3848b76c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training data:\",len(train_loader),\"Validation data:\",len(val_loader),\"Test data: \",len(test_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCYSoozY7le1",
        "outputId": "dc592abb-e721-4ed6-e387-0bfb5f59ab28"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data: 400 Validation data: 100 Test data:  10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda=True\n",
        "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")"
      ],
      "metadata": {
        "id": "AO8qLZ7w8W6W"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \"\"\"\n",
        "            input   - (3, 32, 32)\n",
        "            block 1 - (32, 32, 32)\n",
        "            maxpool - (32, 16, 16)\n",
        "            block 2 - (64, 16, 16)\n",
        "            maxpool - (64, 8, 8)\n",
        "            block 3 - (128, 8, 8)\n",
        "            maxpool - (128, 4, 4)\n",
        "            block 4 - (128, 4, 4)\n",
        "            avgpool - (128, 1, 1), reshpe to (128,)\n",
        "            fc      - (128,) -> (10,)\n",
        "        \"\"\"\n",
        "        # block 1\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "        # block 2\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # block 3\n",
        "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "        # block 4\n",
        "        self.conv7 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.conv8 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # block 1\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.bn1(self.conv2(x)))\n",
        "\n",
        "        # maxpool\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        # block 2\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.bn2(self.conv4(x)))\n",
        "\n",
        "        # maxpool\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        # block 3\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = F.relu(self.bn3(self.conv6(x)))\n",
        "\n",
        "        # maxpool\n",
        "        x = F.max_pool2d(x, 2)\n",
        "\n",
        "        # block 4\n",
        "        x = F.relu(self.conv7(x))\n",
        "        x = F.relu(self.bn4(self.conv8(x)))\n",
        "\n",
        "        # avgpool and reshape to 1D\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # fc\n",
        "        x = self.fc(x)\n",
        "\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "_OCmnJB8sdei"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001, betas=(0.9, 0.999))\n",
        "criterion = nn.NLLLoss()\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)"
      ],
      "metadata": {
        "id": "xOvcPqlS8C2W"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model,device,train_loader,val_loader,epochs):\n",
        "  data_loader = {'train':train_loader,'val':val_loader}\n",
        "  print(\"Fitting the model...\")\n",
        "  train_loss,val_loss=[],[]\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    loss_per_epoch,val_loss_per_epoch=0,0\n",
        "\n",
        "    for phase in ('train','val'):\n",
        "      for i,data in enumerate(data_loader[phase]):\n",
        "\n",
        "        input,label  = data[0].to(device),data[1].to(device)\n",
        "\n",
        "        output = model(input)\n",
        "        #calculating loss on the output\n",
        "        loss = criterion(output,label)\n",
        "\n",
        "        if phase == 'train':\n",
        "          optimizer.zero_grad()\n",
        "          #grad calc w.r.t Loss func\n",
        "          loss.backward()\n",
        "          #update weights\n",
        "          optimizer.step()\n",
        "          loss_per_epoch+=loss.item()\n",
        "        else:\n",
        "          val_loss_per_epoch+=loss.item()\n",
        "\n",
        "    scheduler.step(val_loss_per_epoch/len(val_loader))\n",
        "    print(\"Epoch: {} Loss: {} Val_Loss: {}\".format(epoch+1,loss_per_epoch/len(train_loader),val_loss_per_epoch/len(val_loader)))\n",
        "    train_loss.append(loss_per_epoch/len(train_loader))\n",
        "    val_loss.append(val_loss_per_epoch/len(val_loader))\n",
        "  return train_loss,val_loss"
      ],
      "metadata": {
        "id": "LlwHpwlE8Hg2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss,val_loss=fit(model,device,train_loader,val_loader,30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ot4gpnVM9EfW",
        "outputId": "1a7a3b84-1843-424d-8613-b83b5403ddbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting the model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(5,5))\n",
        "plt.plot(np.arange(1,31), loss, \"*-\",label=\"Loss\")\n",
        "plt.plot(np.arange(1,31), val_loss,\"o-\",label=\"Val Loss\")\n",
        "plt.xlabel(\"Num of epochs\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sH_YIx4t2x9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fgsm_attack(input,epsilon,data_grad):\n",
        "  pert_out = input + epsilon*data_grad.sign()\n",
        "  pert_out = torch.clamp(pert_out, 0, 1)\n",
        "  return pert_out\n",
        "\n",
        "def ifgsm_attack(input,epsilon,data_grad):\n",
        "  iter = 10\n",
        "  alpha = epsilon/iter\n",
        "  pert_out = input\n",
        "  for i in range(iter-1):\n",
        "    pert_out = pert_out + alpha*data_grad.sign()\n",
        "    pert_out = torch.clamp(pert_out, 0, 1)\n",
        "    if torch.norm((pert_out-input),p=float('inf')) > epsilon:\n",
        "      break\n",
        "  return pert_out\n"
      ],
      "metadata": {
        "id": "k0y39eZB9Fgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "saved = torch.load(\"/content/cifar10_basiccnn.pth (1).tar\", map_location='cpu')\n",
        "model.load_state_dict(saved['state_dict'])\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "F15xvCOCGvJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model,device,test_loader,epsilon,attack):\n",
        "  correct = 0\n",
        "\n",
        "\n",
        "  for data, target in test_loader:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      data.requires_grad = True\n",
        "      output = model(data)\n",
        "\n",
        "      init_pred = output.max(1, keepdim=True)[1]\n",
        "\n",
        "\n",
        "      if init_pred.item() != target.item():\n",
        "          continue\n",
        "\n",
        "      loss = F.nll_loss(output, target)\n",
        "      model.zero_grad()\n",
        "      loss.backward()\n",
        "      data_grad = data.grad.data\n",
        "\n",
        "      if attack == \"fgsm\":\n",
        "        perturbed_data = fgsm_attack(data,epsilon,data_grad)\n",
        "      elif attack == \"ifgsm\":\n",
        "        perturbed_data = ifgsm_attack(data,epsilon,data_grad)\n",
        "\n",
        "\n",
        "      output = model(perturbed_data)\n",
        "      final_pred = output.max(1, keepdim=True)[1]\n",
        "\n",
        "      if final_pred.item() == target.item():\n",
        "          correct += 1\n",
        "\n",
        "  final_acc = correct/float(len(test_loader))\n",
        "  print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
        "\n",
        "  return final_acc\n"
      ],
      "metadata": {
        "id": "7aoMvjE7-Art"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epsilons = [0,0.007,0.01,0.02,0.03,0.05,0.1,0.2,0.3]\n",
        "for attack in (\"fgsm\",\"ifgsm\"):\n",
        "\n",
        "\n",
        "  print(\"Attack----------->\",attack)\n",
        "  accuracies = []\n",
        "\n",
        "\n",
        "  for eps in epsilons:\n",
        "      acc= test(model, device,test_loader,eps,attack)\n",
        "      accuracies.append(acc)\n",
        "\n",
        "  plt.figure(figsize=(5,5))\n",
        "  plt.plot(epsilons, accuracies, \"*-\")\n",
        "  plt.title(attack)\n",
        "  plt.xlabel(\"Epsilon\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "cOIGhphi-vIn",
        "outputId": "9405823b-0cb6-4918-a8b7-1e7cf415162e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attack-----------> fgsm\n",
            "Epsilon: 0\tTest Accuracy = 3244 / 10000 = 0.3244\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-6f864410ca63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0meps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepsilons\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0maccuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-3a24c77dc1ae>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, device, test_loader, epsilon, attack)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperturbed_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0mfinal_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mfinal_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fgsm_attack(input,epsilon,data_grad):\n",
        "\n",
        "  pert_out = input + epsilon*data_grad.sign()\n",
        "  pert_out = torch.clamp(pert_out, 0, 1)\n",
        "\n",
        "  return pert_out\n",
        "\n",
        "def ifgsm_attack(input,epsilon,data_grad):\n",
        "  iter = 10\n",
        "  alpha = epsilon/iter\n",
        "  pert_out = input\n",
        "  for i in range(iter-1):\n",
        "    pert_out = pert_out + alpha*data_grad.sign()\n",
        "    pert_out = torch.clamp(pert_out, 0, 1)\n",
        "    if torch.norm((pert_out-input),p=float('inf')) > epsilon:\n",
        "      break\n",
        "  return pert_out\n",
        "\n"
      ],
      "metadata": {
        "id": "lVR8sV_VsGLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model,device,optimizer,scheduler,criterion,train_loader,val_loader,Temp,epochs):\n",
        "\n",
        "\n",
        "  data_loader = {'train':train_loader,'val':val_loader}\n",
        "  print(\"Fitting the model...\")\n",
        "\n",
        "  train_loss,val_loss=[],[]\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    loss_per_epoch,val_loss_per_epoch=0,0\n",
        "    for phase in ('train','val'):\n",
        "\n",
        "      for i,data in enumerate(data_loader[phase]):\n",
        "\n",
        "        input,label  = data[0].to(device),data[1].to(device)\n",
        "        output = model(input)\n",
        "        output = F.log_softmax(output/Temp,dim=1)\n",
        "        #calculating loss on the output\n",
        "        loss = criterion(output,label)\n",
        "        if phase == 'train':\n",
        "          optimizer.zero_grad()\n",
        "          #grad calc w.r.t Loss func\n",
        "          loss.backward()\n",
        "          #update weights\n",
        "          optimizer.step()\n",
        "          loss_per_epoch+=loss.item()\n",
        "        else:\n",
        "          val_loss_per_epoch+=loss.item()\n",
        "    scheduler.step(val_loss_per_epoch/len(val_loader))\n",
        "\n",
        "    print(\"Epoch: {} Loss: {} Val_Loss: {}\".format(epoch+1,loss_per_epoch/len(train_loader),val_loss_per_epoch/len(val_loader)))\n",
        "    train_loss.append(loss_per_epoch/len(train_loader))\n",
        "    val_loss.append(val_loss_per_epoch/len(val_loader))\n",
        "  return train_loss,val_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def test(model,device,test_loader,epsilon,Temp,attack):\n",
        "  correct=0\n",
        "  adv_examples = []\n",
        "  for data, target in test_loader:\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    data.requires_grad = True\n",
        "    output = model(data)\n",
        "    output = F.log_softmax(output/Temp,dim=1)\n",
        "    init_pred = output.max(1, keepdim=True)[1]\n",
        "\n",
        "    if init_pred.item() != target.item():\n",
        "        continue\n",
        "\n",
        "    loss = F.nll_loss(output, target)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    data_grad = data.grad.data\n",
        "\n",
        "    if attack == \"fgsm\":\n",
        "      perturbed_data = fgsm_attack(data,epsilon,data_grad)\n",
        "    elif attack == \"ifgsm\":\n",
        "      perturbed_data = ifgsm_attack(data,epsilon,data_grad)\n",
        "\n",
        "\n",
        "    output = model(perturbed_data)\n",
        "    final_pred = output.max(1, keepdim=True)[1]\n",
        "    if final_pred.item() == target.item():\n",
        "        correct += 1\n",
        "\n",
        "\n",
        "  final_acc = correct/float(len(test_loader))\n",
        "  print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
        "\n",
        "  return final_acc,adv_examples"
      ],
      "metadata": {
        "id": "6tM-11cmsGIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def defense(device,train_loader,val_loader,test_loader,epochs,Temp,epsilons):\n",
        "\n",
        "  modelF = Net().to(device)\n",
        "  optimizerF = optim.Adam(modelF.parameters(),lr=0.0001, betas=(0.9, 0.999))\n",
        "  schedulerF = optim.lr_scheduler.ReduceLROnPlateau(optimizerF, mode='min', factor=0.1, patience=3)\n",
        "\n",
        "  modelF1 = Net().to(device)\n",
        "  optimizerF1 = optim.Adam(modelF1.parameters(),lr=0.0001, betas=(0.9, 0.999))\n",
        "  schedulerF1 = optim.lr_scheduler.ReduceLROnPlateau(optimizerF1, mode='min', factor=0.1, patience=3)\n",
        "\n",
        "  criterion = nn.NLLLoss()\n",
        "\n",
        "  lossF,val_lossF=fit(modelF,device,optimizerF,schedulerF,criterion,train_loader,val_loader,Temp,epochs)\n",
        "  fig = plt.figure(figsize=(5,5))\n",
        "  plt.plot(np.arange(1,epochs+1), lossF, \"*-\",label=\"Loss\")\n",
        "  plt.plot(np.arange(1,epochs+1), val_lossF,\"o-\",label=\"Val Loss\")\n",
        "  plt.title(\"Network F\")\n",
        "  plt.xlabel(\"Num of epochs\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  #converting target labels to soft labels\n",
        "  for data in train_loader:\n",
        "    input, label  = data[0].to(device),data[1].to(device)\n",
        "    softlabel  = F.log_softmax(modelF(input),dim=1)\n",
        "    data[1] = softlabel\n",
        "\n",
        "  lossF1,val_lossF1=fit(modelF1,device,optimizerF1,schedulerF1,criterion,train_loader,val_loader,Temp,epochs)\n",
        "  fig = plt.figure(figsize=(5,5))\n",
        "  plt.plot(np.arange(1,epochs+1), lossF1, \"*-\",label=\"Loss\")\n",
        "  plt.plot(np.arange(1,epochs+1), val_lossF1,\"o-\",label=\"Val Loss\")\n",
        "  plt.title(\"Network F'\")\n",
        "  plt.xlabel(\"Num of epochs\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  model = Net().to(device)\n",
        "  model.load_state_dict(modelF1.state_dict())\n",
        "\n",
        "  for attack in (\"fgsm\",\"ifgsm\"):\n",
        "    accuracies = []\n",
        "    for eps in epsilons:\n",
        "        acc, ex = test(model,device,test_loader,eps,1,attack)\n",
        "        accuracies.append(acc)\n",
        "\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.plot(epsilons, accuracies, \"*-\")\n",
        "    plt.title(attack)\n",
        "    plt.xlabel(\"Epsilon\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "3bfepsuwsGGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Temp=100\n",
        "epochs=10\n",
        "epsilons=[0,0.007,0.01,0.02,0.03,0.05,0.1,0.2,0.3]\n",
        "defense(device,train_loader,val_loader,test_loader,epochs,Temp,epsilons)"
      ],
      "metadata": {
        "id": "m8U7bMJfsGEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r20yxGErsF_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ax9uDw7IsF9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XQCoAwaisF7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-864lGNpsF4n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}